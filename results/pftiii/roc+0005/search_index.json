[["participation-information.html", "roc+0005 ROC 1 Participation Information 1.1 Names 1.2 Dates 1.3 Libraries", " roc+0005 ROC Proprietary Fingerprint Template (PFT) Evaluation III Last Updated: 21 June 2024 1 Participation Information 1.1 Names Information in this section is provided by the participant. Participant Name: ROC PFT III Identifier: roc+0005 PFT III API Version: 1.1.0 Feature Extractor: Marketing Name: ROC SDK v3.2.0 Template Matcher: Marketing Name: ROC SDK v3.2.0 1.2 Dates Application Date: 17 June 2024 First Submission Date: 14 June 2024 (as version 0004) Final Submission Date: 20 June 2024 (as version 0005) Validation Date: 20 June 2024 Completion Date: 21 June 2024 1.3 Libraries Testing completed using Ubuntu 20.04.3 LTS. Table 1.1: Information regarding library and configuration files provided as part of roc+0005. Filename MD5 Checksum Size libicutu.so.66 e52a996730797512d6bdbda16e38b111 220 kB libicuuc.so.66 847a1dc2d266d158449beb5b4229ba45 2 MB libroc.so.3.2.0 37f1fad014b9153c549660ebf6239022 47 MB libicuio.so.66 d8b76e7ef55aa79a367725beeb1e82a9 60 kB libQt5Concurrent.so.5.14 47ce700bc77c3e88816b4dc51327a65c 31 kB libicudata.so.66 2236674edbe8efc94f2f681a6e373cdb 28 MB libpftiii_roc_0005.so df7a8ee15a6a1aecd247f71c0b0d130b 31 kB libicui18n.so.66 053f6f9d58e59a75509e4bf5e2c21f96 3 MB libicutest.so.66 b5e76b46ddafa3671ac90bbe8fa8d240 82 kB libQt5Core.so.5 56beb55e6c63caf0b622281eb7efca2e 7 MB libQt5Concurrent.so.5.14.2 47ce700bc77c3e88816b4dc51327a65c 31 kB libQt5Core.so 56beb55e6c63caf0b622281eb7efca2e 7 MB libQt5Network.so.5 04318595fd24ee8a5c1b0d4eb5aee838 2 MB libQt5Network.so.5.14 04318595fd24ee8a5c1b0d4eb5aee838 2 MB libicutu.so.66.1 e52a996730797512d6bdbda16e38b111 220 kB libicudata.so.66.1 2236674edbe8efc94f2f681a6e373cdb 28 MB libQt5Network.so 04318595fd24ee8a5c1b0d4eb5aee838 2 MB libQt5Core.so.5.14 56beb55e6c63caf0b622281eb7efca2e 7 MB libQt5Core.so.5.14.2 56beb55e6c63caf0b622281eb7efca2e 7 MB libQt5Concurrent.so.5 47ce700bc77c3e88816b4dc51327a65c 31 kB libicuuc.so.66.1 847a1dc2d266d158449beb5b4229ba45 2 MB libicutest.so.66.1 b5e76b46ddafa3671ac90bbe8fa8d240 82 kB libicui18n.so.66.1 053f6f9d58e59a75509e4bf5e2c21f96 3 MB libroc.so.3.2 37f1fad014b9153c549660ebf6239022 47 MB libQt5Network.so.5.14.2 04318595fd24ee8a5c1b0d4eb5aee838 2 MB libroc.so 37f1fad014b9153c549660ebf6239022 47 MB libicuio.so.66.1 d8b76e7ef55aa79a367725beeb1e82a9 60 kB libQt5Concurrent.so 47ce700bc77c3e88816b4dc51327a65c 31 kB libroc_fingerprint_representation.so c285ebed60c43bb784e64fc794410683 117 MB ROC.lic ed6ac4b5e0692079b5d68a3fd7263049 584 B libroc_fingerprint_representation.so.3.2 c285ebed60c43bb784e64fc794410683 117 MB "],["timing-sample-dataset.html", "2 Timing Sample Dataset 2.1 Template Size 2.2 Template Creation Time 2.3 Template Comparison Time", " 2 Timing Sample Dataset A fixed sample of images randomly selected from the PFT III datasets are used to assess whether or not an implementation adheres to the minimum timing requirements set forth in the PFT III test plan. This sample is also used to provide an estimate on template size. The images and comparisons are identical to the “1K Sample Evaluation” from NIST’s PFT II evaluation, with the exception of the “IARPA N2N” dataset, which is new in PFT III. Table 2.1 shows information about the maximum dimensions and resolutions of the images in each of the timing sample datasets. Table 2.1: Maximum dimensions in pixels and capture resolution in pixels per inch (PPI) for the images in each of the subsets comprising the timing sample dataset. AZ LA County DHS 2 POE+BVA IARPA N2N Max Dimensions (pixels) 800 x 800 412 x 1 000 368 x 368 500 x 500 1 600 x 1 500 Resolution (PPI) 500 500 500 500 1 000 2.1 Template Size Figure 2.1 and Table 2.2 show the distribution of file sizes of templates. Failures of any kind reported during template generation result in NIST code writing 0 byte files. These files are excluded from the template size analysis in this section. Figure 2.1: Box plots of template sizes in bytes of templates created from a fixed sample of data from the PFT III evaluation. An overall plot is shown, as well as individual plots per data origin. Tabular versions of this data are shown in Table 2.2. Table 2.2: Sizes in bytes of templates created from a fixed sample of data from the PFT III evaluation. The bottom row, Failures, shows the number of failures to create a template, which are not included in these statistics. Box plots of this data are shown in Figure 2.1. Overall AZ LA County DHS 2 POE+BVA IARPA N2N Min 272 1 552 352 272 432 352 25 % 4 032 6 992 5 872 3 232 3 552 6 592 Median 5 632 7 792 6 672 3 792 4 192 7 712 Mean 5 806 7 836 6 711 3 818 4 220 7 715 75 % 7 392 8 592 7 552 4 432 4 832 8 912 Max 14 192 13 232 12 272 6 832 8 912 14 192 Failures 4 0 1 3 0 0 2.2 Template Creation Time Figure 2.2 and Table 2.3 show the distribution of durations of time consumed when creating templates. Failures of all kinds are incorporated into these statistics, since this time would be observed by the end user of a template creation algorithm. Times are measured by running a single process on an isolated compute node equipped with an Intel Xeon Gold 6254 CPU. Figure 2.2: Box plots of elapsed milliseconds when creating templates from a fixed sample of data from the PFT III evaluation. All times are used, even if a failure occurred. Tabular versions of this data are shown in Table 2.3. Table 2.3: Elapsed milliseconds when creating templates from a fixed sample of data from the PFT III evaluation. All times are used, even if a failure occurred. The bottom row, Failures, shows the number of failures to generate a template. Failures are included in these statistics. Box plots of this data are shown in Figure 2.2. Overall AZ LA County DHS 2 POE+BVA IARPA N2N Min 235.2 289.1 243.6 235.2 245.6 268.7 25 % 306.9 381.3 350.0 290.8 299.0 375.7 Median 345.9 394.4 364.1 300.8 310.7 395.8 Mean 347.5 395.9 364.7 300.7 312.5 396.3 75 % 384.7 409.6 378.9 311.3 324.3 416.2 Max 656.6 562.6 549.6 482.3 461.5 656.6 Failures 4 0 1 3 0 0 2.3 Template Comparison Time Figure 2.3 and Table 2.4 show the distribution of durations of time consumed when comparing templates. Failures of any kind are incorporated into these statistics, since this time would be observed by the end user of a template comparison algorithm. Times are measured by running a single process on an isolated compute node equipped with an Intel Xeon Gold 6254 CPU. Figure 2.3: Box plots of elapsed microseconds when comparing two templates from a fixed sample of data from the PFT III evaluation. All times are used, even if a failure occurred. Tabular versions of this data are shown in Table 2.4. Table 2.4: Elapsed microseconds when comparing two templates from a fixed sample of data from the PFT III evaluation. The bottom row, Failures, shows the number of failures to compare. Failures are included in these statistics. Box plots of this data are shown in Figure 2.4. Overall AZ LA County DHS 2 POE+BVA IARPA N2N Min 0.1 0.2 0.2 0.1 0.2 0.1 25 % 0.4 0.6 0.5 0.3 0.5 0.2 Median 0.6 0.7 0.6 0.5 0.7 0.3 Mean 2 963.6 805.8 3 103.6 5 344.2 2 778.2 2 783.4 75 % 0.7 0.9 0.7 0.6 0.8 0.6 Max 1 628 011.4 1 609 932.5 1 628 011.4 1 611 490.5 1 587 107.2 1 598 369.3 Failures 0 0 0 0 0 0 "],["pft-iii-datasets.html", "3 PFT III Datasets 3.1 Arizona Department of Public Safety 3.2 Los Angeles County Sheriff’s Department 3.3 Port of Entry, BioVisa Application 3.4 US VISIT #2 3.5 IARPA Nail-to-Nail", " 3 PFT III Datasets Although large tests, both PFT and PFT II only used subsets of data available from the Arizona Department of Public Safety, the Los Angeles County Sheriff’s Department, and the Department of Homeland Security. For PFT III, NIST is using new subject comparisons from each of these datasets. Additionally, PFT III adds comparisons of public and sequestered data collected as part of the Intelligence Advanced Research Project Activity (IARPA)’s Nail-to-Nail (N2N) Challenge. 3.1 Arizona Department of Public Safety The Arizona Department of Public Safety (AZDPS) dataset consists of plain and rolled impressions of all ten fingers. Figure 3.1 and Table 3.1 show the detection error tradeoff (DET) curves of all fingers not compared in other PFT tests. This data is separated by finger position in Figure 3.2 and Table 3.2 and again by impression type in Figure 3.3 and Table 3.3. Values made by combinations of fingers were generated by summing the individual similarity scores for comparisons of the individual finger and dividing by the number of values added. This technique is known as sum fusion. Figure 3.1: Detection error tradeoff of all comparisons from all fingers in the PFT III AZDPS dataset. Numbers in gray indicate the similarity threshold. Table 3.1: False non-match rate values at specific false match rates for all comparisons from all fingers in the PFT III AZDPS dataset FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 0.0048 0.0043 0.0038 Figure 3.2: Detection error tradeoff of all comparisons from all fingers in the PFT III AZDPS dataset, separated by finger position. Combined finger positions were generated by sum fusion. Table 3.2: False non-match rate values at specific false match rates for all comparisons from all fingers in the PFT III AZDPS dataset, separated by finger position. Combined finger positions were generated by sum fusion. FRGP FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 R Thumb 0.0039 0.0036 0.0033 R Index 0.0046 0.0041 0.0035 R Middle 0.0048 0.0045 0.0041 R Ring 0.0042 0.0037 0.0033 R Little 0.0054 0.0047 0.0038 L Thumb 0.0039 0.0037 0.0034 L Index 0.0049 0.0045 0.0039 L Middle 0.0050 0.0047 0.0042 L Ring 0.0048 0.0043 0.0038 L Little 0.0069 0.0056 0.0045 R &amp; L Thumb 0.0022 0.0021 0.0019 R &amp; L Index 0.0014 0.0013 0.0013 R &amp; L Middle 0.0017 0.0016 0.0015 R &amp; L Ring 0.0016 0.0015 0.0013 R &amp; L Little 0.0016 0.0015 0.0013 R Index &amp; Ring 0.0022 0.0021 0.0019 L Index &amp; Ring 0.0027 0.0025 0.0023 R Slap 0.0016 0.0016 0.0015 L Slap 0.0019 0.0018 0.0016 R Hand 0.0012 0.0012 0.0011 L Hand 0.0013 0.0012 0.0011 Figure 3.3: Detection error tradeoff of all comparisons from all fingers in the PFT III AZDPS dataset, separated by finger position and impression type. Combined finger positions were generated by sum fusion. Table 3.3: False non-match rate values at specific false match rates for all comparisons from all fingers in the PFT III AZDPS dataset, separated by finger position and impression type. Combined finger positions were generated by sum fusion. FRGP FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 Plain to Plain R Thumb 0.0047 0.0043 0.0041 R Index 0.0071 0.0063 0.0053 R Middle 0.0069 0.0064 0.0059 R Ring 0.0057 0.0051 0.0046 R Little 0.0069 0.0057 0.0044 L Thumb 0.0047 0.0045 0.0041 L Index 0.0062 0.0055 0.0048 L Middle 0.0065 0.0061 0.0053 L Ring 0.0058 0.0050 0.0042 L Little 0.0102 0.0080 0.0064 R &amp; L Thumb 0.0027 0.0025 0.0023 R &amp; L Index 0.0016 0.0015 0.0013 R &amp; L Middle 0.0020 0.0019 0.0018 R &amp; L Ring 0.0019 0.0016 0.0014 R &amp; L Little 0.0017 0.0016 0.0014 R Index &amp; Ring 0.0029 0.0027 0.0024 L Index &amp; Ring 0.0032 0.0030 0.0027 R Slap 0.0020 0.0020 0.0020 L Slap 0.0026 0.0025 0.0021 R Hand 0.0012 0.0012 0.0011 L Hand 0.0013 0.0013 0.0011 Plain to Rolled R Thumb 0.0038 0.0035 0.0032 R Index 0.0045 0.0040 0.0034 R Middle 0.0047 0.0043 0.0039 R Ring 0.0039 0.0035 0.0030 R Little 0.0051 0.0043 0.0034 L Thumb 0.0039 0.0037 0.0033 L Index 0.0047 0.0043 0.0037 L Middle 0.0048 0.0045 0.0039 L Ring 0.0045 0.0041 0.0036 L Little 0.0065 0.0053 0.0041 R &amp; L Thumb 0.0021 0.0020 0.0019 R &amp; L Index 0.0012 0.0012 0.0011 R &amp; L Middle 0.0015 0.0014 0.0013 R &amp; L Ring 0.0014 0.0012 0.0011 R &amp; L Little 0.0012 0.0011 0.0010 R Index &amp; Ring 0.0020 0.0019 0.0017 L Index &amp; Ring 0.0025 0.0024 0.0021 R Slap 0.0015 0.0015 0.0014 L Slap 0.0018 0.0017 0.0015 R Hand 0.0011 0.0010 0.0010 L Hand 0.0011 0.0011 0.0010 Rolled to Rolled R Thumb 0.0036 0.0034 0.0031 R Index 0.0027 0.0025 0.0022 R Middle 0.0036 0.0034 0.0030 R Ring 0.0035 0.0034 0.0030 R Little 0.0051 0.0048 0.0044 L Thumb 0.0033 0.0031 0.0029 L Index 0.0043 0.0042 0.0039 L Middle 0.0042 0.0040 0.0036 L Ring 0.0048 0.0044 0.0040 L Little 0.0047 0.0042 0.0037 R &amp; L Thumb 0.0021 0.0020 0.0018 R &amp; L Index 0.0019 0.0019 0.0018 R &amp; L Middle 0.0020 0.0019 0.0018 R &amp; L Ring 0.0023 0.0022 0.0021 R &amp; L Little 0.0026 0.0025 0.0024 R Index &amp; Ring 0.0022 0.0022 0.0019 L Index &amp; Ring 0.0027 0.0026 0.0025 R Slap 0.0017 0.0017 0.0016 L Slap 0.0017 0.0016 0.0015 R Hand 0.0017 0.0016 0.0015 L Hand 0.0017 0.0016 0.0016 3.2 Los Angeles County Sheriff’s Department The Los Angeles County Sheriff’s Department (LASD) dataset consists of plain and rolled impressions of all ten fingers, captured with a mixture of ink and optical devices. Figure 3.4 and Table 3.4 show the DET of all fingers not compared in other PFT subsets. This data is separated by finger position in Figure 3.5 and Table 3.5 and again by impression type in Figure 3.6 and Table 3.6. Curves made by combinations of fingers were generated by sum fusion. Figure 3.4: Detection error tradeoff of all comparisons from all fingers in the PFT III LASD dataset. Numbers in gray indicate the similarity threshold. Table 3.4: False non-match rate values at specific false match rates for the PFT III Los Angeles County Sheriff’s Department dataset overall. FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 0.008 0.0075 0.0068 Figure 3.5: Detection error tradeoff of all comparisons from all fingers in the PFT III LASD dataset, separated by finger position. Combined finger positions were generated by sum fusion. Table 3.5: False non-match rate values at specific false match rates for the PFT III LASD dataset, separated by finger position. Combined finger positions were generated by sum fusion. FRGP FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 R Thumb 0.0037 0.0035 0.0033 R Index 0.0065 0.0060 0.0052 R Middle 0.0099 0.0095 0.0090 R Ring 0.0084 0.0081 0.0076 R Little 0.0066 0.0058 0.0049 L Thumb 0.0030 0.0029 0.0027 L Index 0.0081 0.0075 0.0065 L Middle 0.0143 0.0137 0.0127 L Ring 0.0087 0.0083 0.0077 L Little 0.0111 0.0098 0.0081 R &amp; L Thumb 0.0022 0.0022 0.0022 R &amp; L Index 0.0017 0.0017 0.0016 R &amp; L Middle 0.0027 0.0027 0.0025 R &amp; L Ring 0.0018 0.0018 0.0017 R &amp; L Little 0.0019 0.0018 0.0017 R Index &amp; Ring 0.0025 0.0024 0.0022 L Index &amp; Ring 0.0043 0.0042 0.0038 R Slap 0.0016 0.0016 0.0015 L Slap 0.0027 0.0026 0.0025 R Hand 0.0012 0.0012 0.0012 L Hand 0.0013 0.0013 0.0013 Figure 3.6: Detection error tradeoff of all comparisons from all fingers in the PFT III LASD dataset, separated by finger position and impression type. Combined finger positions were generated by sum fusion. Table 3.6: False non-match rate values at specific false match rates for the PFT III LASD dataset, separated by finger position and impression type. Combined finger positions were generated by sum fusion. FRGP FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 Plain to Plain R Thumb 0.0050 0.0047 0.0042 R Index 0.0104 0.0093 0.0079 R Middle 0.0188 0.0180 0.0171 R Ring 0.0156 0.0150 0.0142 R Little 0.0109 0.0091 0.0071 L Thumb 0.0036 0.0035 0.0034 L Index 0.0146 0.0134 0.0117 L Middle 0.0284 0.0274 0.0253 L Ring 0.0170 0.0162 0.0152 L Little 0.0224 0.0195 0.0160 R &amp; L Thumb 0.0030 0.0030 0.0029 R &amp; L Index 0.0020 0.0020 0.0019 R &amp; L Middle 0.0046 0.0046 0.0043 R &amp; L Ring 0.0022 0.0021 0.0020 R &amp; L Little 0.0022 0.0020 0.0018 R Index &amp; Ring 0.0034 0.0033 0.0030 L Index &amp; Ring 0.0081 0.0078 0.0071 R Slap 0.0020 0.0019 0.0018 L Slap 0.0053 0.0051 0.0046 R Hand 0.0013 0.0013 0.0012 L Hand 0.0012 0.0012 0.0012 Plain to Rolled R Thumb 0.0034 0.0033 0.0032 R Index 0.0066 0.0061 0.0054 R Middle 0.0092 0.0089 0.0084 R Ring 0.0074 0.0069 0.0066 R Little 0.0062 0.0055 0.0048 L Thumb 0.0028 0.0027 0.0026 L Index 0.0073 0.0066 0.0056 L Middle 0.0137 0.0130 0.0121 L Ring 0.0071 0.0067 0.0061 L Little 0.0095 0.0083 0.0065 R &amp; L Thumb 0.0022 0.0021 0.0021 R &amp; L Index 0.0017 0.0017 0.0017 R &amp; L Middle 0.0026 0.0025 0.0023 R &amp; L Ring 0.0018 0.0018 0.0018 R &amp; L Little 0.0018 0.0017 0.0016 R Index &amp; Ring 0.0024 0.0023 0.0021 L Index &amp; Ring 0.0034 0.0033 0.0029 R Slap 0.0016 0.0015 0.0014 L Slap 0.0018 0.0017 0.0017 R Hand 0.0012 0.0012 0.0012 L Hand 0.0014 0.0014 0.0014 Rolled to Rolled R Thumb 0.0027 0.0026 0.0025 R Index 0.0031 0.0030 0.0026 R Middle 0.0029 0.0027 0.0026 R Ring 0.0032 0.0031 0.0029 R Little 0.0036 0.0035 0.0033 L Thumb 0.0025 0.0024 0.0023 L Index 0.0033 0.0032 0.0029 L Middle 0.0027 0.0026 0.0025 L Ring 0.0031 0.0030 0.0028 L Little 0.0030 0.0028 0.0028 R &amp; L Thumb 0.0015 0.0015 0.0014 R &amp; L Index 0.0015 0.0014 0.0014 R &amp; L Middle 0.0014 0.0014 0.0013 R &amp; L Ring 0.0015 0.0015 0.0015 R &amp; L Little 0.0017 0.0017 0.0017 R Index &amp; Ring 0.0019 0.0019 0.0016 L Index &amp; Ring 0.0019 0.0018 0.0018 R Slap 0.0014 0.0014 0.0013 L Slap 0.0014 0.0014 0.0013 R Hand 0.0012 0.0012 0.0012 L Hand 0.0013 0.0013 0.0013 3.3 Port of Entry, BioVisa Application The Port of Entry/BioVisa Application (POE+BVA) dataset consists of plain impressions of index fingers. Figure 3.7 and Table 3.7 show the DET of all fingers not compared in other PFT subsets. This data is separated by finger position in Figure 3.8. Curves made by combinations of fingers were generated by sum fusion. Figure 3.7: Detection error tradeoff of all comparisons from all fingers in the PFT III POE+BVA dataset Numbers in gray indicate the similarity threshold. Table 3.7: False non-match rate values at specific false match rates for the PFT III POE+BVA dataset overall. FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 0.005 0.0048 0.0043 Figure 3.8: Detection error tradeoff of comparisons from the PFT III POE+BVA dataset, separated by finger position. Combined finger positions were generated by sum fusion. Table 3.8: False non-match rate values at specific false match rates for the PFT III POE+BVA dataset, separated by finger position. Combined finger positions were generated by sum fusion. FRGP FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 R Index 0.0046 0.0045 0.0041 L Index 0.0054 0.0050 0.0045 R &amp; L Index 0.0008 0.0008 0.0007 3.4 US VISIT #2 The US VISIT #2 (VISIT2) dataset consists of plain impressions of index fingers and are similar to POE+BVA. Figure 3.9 and Table 3.9 show the DET of all fingers not compared in other PFT subsets. This data is separated by finger position in Figure 3.10. Curves made by combinations of fingers were generated by sum fusion. Figure 3.9: Detection error tradeoff of all comparisons from all fingers in the PFT III VISIT2 dataset. Numbers in gray indicate the similarity threshold. Table 3.9: False non-match rate values at specific false match rates for the PFT III VISIT2 dataset overall. FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 0.0051 0.0048 0.0044 Figure 3.10: Detection error tradeoff of comparisons from the PFT III VISIT2 dataset, separated by finger position. Combined finger positions were generated by sum fusion. Table 3.10: False non-match rate values at specific false match rates for the PFT III VISIT2 dataset, separated by finger position. FRGP FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 R Index 0.0059 0.0056 0.0052 L Index 0.0043 0.0040 0.0037 R &amp; L Index 0.0017 0.0016 0.0015 3.5 IARPA Nail-to-Nail In September 2017, IARPA held a fingerprint data collection as part of the Nail to Nail Fingerprint Challenge. Participating Challengers deployed devices to capture a rolled-equivalent print. Approximately two-thirds of the ten-print data collected was released to the public as NIST Special Database 302, with the rest being sequestered at NIST for evaluations like PFT III. Information about the Challenge can be found in NIST IR 8210. Descriptions of the devices described by the device codes in the following figures and tables can be found in NIST TN 2007. 3.5.1 By Device The following figures and tables show the DET of all comparisons from select devices in the IARPA N2N Challenge. All probe devices imaged natively at 500 PPI, except for J, R, and U, which imaged at 1 000 PPI. The reference device, V, also imaged natively at 1 000 PPI. When these higher resolution devices are shown at 500 PPI, they were downsampled using NIST Fingerprint Image Resampler (NFIR). Figure 3.11 and Table 3.11 show results with 500 PPI probes against 1 000 PPI references. Figure 3.12 and Table 3.12 show the same probe images against reference images downsampled to the same resolution. Figure 3.13 and Table 3.13 show native 1 000 PPI to 1 000 PPI comparisons for supported devices. Figure 3.11: Overall detection error tradeoff of comparisons from the PFT III IARPA N2N dataset, using probe images at 500 PPI and reference images at their native 1 000 PPI resolution. Table 3.11: False non-match rate values at specific false match rates for devices deployed in the IARPA N2N Challenge at 500 PPI compared to a 1 000 PPI reference roll. Device FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 A 0.0039 0.0027 0.0015 B 0.0383 0.0350 0.0284 C 0.0053 0.0050 0.0035 E 0.0068 0.0059 0.0047 F 0.0058 0.0029 0.0020 J 0.0049 0.0049 0.0049 K 0.0040 0.0035 0.0006 M 0.0083 0.0065 0.0038 P 0.0000 0.0000 0.0000 R 0.0020 0.0020 0.0020 S 0.0021 0.0015 0.0005 U 0.0009 0.0006 0.0003 Figure 3.12: Overall detection error tradeoff of comparisons from the PFT III IARPA N2N dataset, using probe images at 500 PPI and reference images downsampled to 500 PPI. Table 3.12: False non-match rate values at specific false match rates for devices deployed in the IARPA N2N Challenge at 500 PPI compared to a downsampled 500 PPI reference roll. Device FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 A 0.0039 0.0027 0.0021 B 0.0386 0.0350 0.0293 C 0.0055 0.0050 0.0035 E 0.0065 0.0059 0.0050 F 0.0053 0.0032 0.0020 J 0.0049 0.0049 0.0049 K 0.0040 0.0029 0.0006 M 0.0086 0.0062 0.0035 P 0.0000 0.0000 0.0000 R 0.0020 0.0020 0.0007 S 0.0021 0.0015 0.0005 U 0.0009 0.0006 0.0003 Figure 3.13: Overall detection error tradeoff of comparisons from the PFT III IARPA N2N dataset for devices that supported native 1 000 PPI to 1 000 PPI comparisons. Table 3.13: False non-match rate values at specific false match rates for 1 000 PPI devices deployed in the IARPA N2N Challenge compared to a 1 000 PPI reference roll. Device FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 J 0.0049 0.0049 0.0049 R 0.0020 0.0020 0.0020 U 0.0012 0.0003 0.0000 3.5.2 Resample Test PFT III supports encoding of variable resolution images. It is thought that several fingerprint feature extractors downsample imagery to a lower resolution before extracting features. To test this theory, we downsample and compare source and reference imagery both captured natively at 1 000 PPI. All downsampling was performed using NFIR. Images were compared at all combinations of 100, 250, 300, 333, 500, 600, and 1 000 (native) PPI. Figure 3.14 and Table 3.14 show match rates against 1 000 PPI references. Figure 3.15 and Table 3.15 show match rates against 600 PPI downsampled references. Figure 3.16 and Table 3.16 show match rates against 500 PPI downsampled references. Figure 3.17 and Table 3.17 show match rates against 333 PPI downsampled references. Figure 3.18 and Table 3.18 show match rates against 300 PPI downsampled references. Figure 3.19 and Table 3.19 show match rates against 250 PPI downsampled references. Figure 3.20 and Table 3.20 show match rates against 100 PPI downsampled references. Figure 3.14: Detection error tradeoff of comparisons from the PFT III IARPA N2N dataset using downsampled probe images of various resolutions as compared to 1 000 (native) images. Table 3.14: False non-match rate values at specific false match rates for device U from the IARPA N2N Challenge at various resolutions compared to 1 000 (native) reference rolls from device V. Probe Resolution (PPI) FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 100 0.7965 0.7041 0.5924 250 0.0012 0.0009 0.0009 300 0.0009 0.0009 0.0006 333 0.0012 0.0009 0.0003 500 0.0009 0.0006 0.0003 600 0.0009 0.0009 0.0006 1 000 0.0012 0.0003 0.0000 Figure 3.15: Detection error tradeoff of comparisons from the PFT III IARPA N2N dataset using downsampled probe images of various resolutions as compared to downsampled 600 PPI images. Table 3.15: False non-match rate values at specific false match rates for device U from the IARPA N2N Challenge at various resolutions compared to downsampled 600 PPI reference rolls from device V. Probe Resolution (PPI) FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 100 0.7942 0.7035 0.5883 250 0.0009 0.0009 0.0009 300 0.0009 0.0009 0.0006 333 0.0012 0.0009 0.0003 500 0.0009 0.0006 0.0003 600 0.0012 0.0009 0.0006 1 000 0.0012 0.0003 0.0000 Figure 3.16: Detection error tradeoff of comparisons from the PFT III IARPA N2N dataset using downsampled probe images of various resolutions as compared to downsampled 500 PPI images. Table 3.16: False non-match rate values at specific false match rates for device U from the IARPA N2N Challenge at various resolutions compared to downsampled 500 PPI reference rolls from device V. Probe Resolution (PPI) FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 100 0.7924 0.7053 0.5909 250 0.0012 0.0009 0.0009 300 0.0009 0.0009 0.0003 333 0.0015 0.0006 0.0003 500 0.0009 0.0006 0.0003 600 0.0012 0.0009 0.0006 1 000 0.0012 0.0003 0.0000 Figure 3.17: Detection error tradeoff of comparisons from the PFT III IARPA N2N dataset using downsampled probe images of various resolutions as compared to downsampled 333 PPI images. Table 3.17: False non-match rate values at specific false match rates for device U from the IARPA N2N Challenge at various resolutions compared to downsampled 333 PPI reference rolls from device V. Probe Resolution (PPI) FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 100 0.8000 0.7102 0.5889 250 0.0012 0.0009 0.0009 300 0.0009 0.0009 0.0003 333 0.0012 0.0006 0.0003 500 0.0009 0.0009 0.0003 600 0.0009 0.0009 0.0006 1 000 0.0012 0.0003 0.0000 Figure 3.18: Detection error tradeoff of comparisons from the PFT III IARPA N2N dataset using downsampled probe images of various resolutions as compared to downsampled 300 PPI images. Table 3.18: False non-match rate values at specific false match rates for device U from the IARPA N2N Challenge at various resolutions compared to downsampled 300 PPI reference rolls from device V. Probe Resolution (PPI) FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 100 0.7977 0.7070 0.5868 250 0.0009 0.0009 0.0009 300 0.0009 0.0009 0.0006 333 0.0012 0.0006 0.0003 500 0.0009 0.0006 0.0000 600 0.0009 0.0009 0.0006 1 000 0.0012 0.0006 0.0000 Figure 3.19: Detection error tradeoff of comparisons from the PFT III IARPA N2N dataset using downsampled probe images of various resolutions as compared to downsampled 250 PPI images. Table 3.19: False non-match rate values at specific false match rates for device U from the IARPA N2N Challenge at various resolutions compared to downsampled 250 PPI reference rolls from device V. Probe Resolution (PPI) FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 100 0.8018 0.7067 0.5877 250 0.0006 0.0006 0.0006 300 0.0009 0.0009 0.0006 333 0.0012 0.0006 0.0006 500 0.0009 0.0003 0.0003 600 0.0009 0.0009 0.0006 1 000 0.0009 0.0003 0.0000 Figure 3.20: Detection error tradeoff of comparisons from the PFT III IARPA N2N dataset using downsampled probe images of various resolutions as compared to downsampled 100 PPI images. Table 3.20: False non-match rate values at specific false match rates for device U from the IARPA N2N Challenge at various resolutions compared to downsampled 100 PPI reference rolls from device V. Probe Resolution (PPI) FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 100 0.9953 0.9646 0.7301 250 0.8012 0.7167 0.5787 300 0.7947 0.7132 0.5798 333 0.8012 0.7123 0.5795 500 0.8091 0.7184 0.5842 600 0.7997 0.7137 0.5810 1 000 0.8056 0.7158 0.5839 "],["comparison-to-pft-ii.html", "4 Comparison to PFT II 4.1 All Fingers 4.2 Index Fingers 4.3 Arizona/Los Angeles County", " 4 Comparison to PFT II The PFT II evaluation ran at NIST from February 2010 until May 2019. The plots and tables in this section use identical datasets and comparison pairs as PFT II and are directly comparable to results posted on the NIST website for PFT II: https://nist.gov/itl/iad/image-group/proprietary-fingerprint-template-evaluation-pftii 4.1 All Fingers Figure 4.1 and Table 4.1 shows the DET of all fingers for each dataset evaluated in PFT II. Curves are linked at equivalent score thresholds for specific false match rates on the best performing dataset. Figure 4.1: Detection error tradeoff of all comparisons from all fingers in PFT II, separated by dataset. Curves are linked at equivalent score thresholds. Table 4.1: False non-match rate values at specific false match rates for the PFT II datasets combined. Dataset FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 PFT II: AZ+LA County 0.0041 0.0038 0.0035 PFT II: DHS2 0.0216 0.0203 0.0175 PFT II: POE+BVA 0.0027 0.0025 0.0022 4.2 Index Fingers Figure 4.2 and Table 4.2 show the DET of index fingers over the three datasets evaluated in PFT II. Combined finger positions were generated by sum fusion. Figure 4.2: Detection error tradeoff of index fingers compared in PFT II. Combined finger positions were generated by sum fusion. Table 4.2: False non-match rate values at specific false match rates for the PFT II datasets. FRGP FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 PFT II: AZ+LA County R Index 0.0033 0.0030 0.0026 L Index 0.0049 0.0045 0.0039 R &amp; L Index 0.0007 0.0007 0.0006 PFT II: DHS2 R Index 0.0224 0.0212 0.0183 L Index 0.0206 0.0194 0.0166 R &amp; L Index 0.0183 0.0169 0.0139 PFT II: POE+BVA R Index 0.0015 0.0014 0.0013 L Index 0.0040 0.0037 0.0032 R &amp; L Index 0.0001 0.0001 0.0000 4.3 Arizona/Los Angeles County Figure 4.3 and Table 4.3 show the DET of all finger combinations compared in PFT II’s evaluation of the combined datasets from the Arizona Department of Public Safety and the Los Angeles County Sheriff’s Department. Curves in each dataset are separated by the impression types compared. Combined finger positions were generated by sum fusion. Figure 4.3: Detection error tradeoff of comparisons from the PFT II AZ/LA dataset, separated by impression type. Combined finger positions were generated by sum fusion. Table 4.3: False non-match rate values at specific false match rates for the PFT II AZ+LA County dataset. FRGP FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 Plain to Plain R Thumb 0.0019 0.0018 0.0016 R Index 0.0048 0.0043 0.0036 R Middle 0.0084 0.0079 0.0073 L Thumb 0.0021 0.0020 0.0018 L Index 0.0069 0.0064 0.0055 L Middle 0.0120 0.0114 0.0106 R &amp; L Thumb 0.0011 0.0011 0.0010 R &amp; L Index 0.0009 0.0007 0.0006 R &amp; L Middle 0.0025 0.0023 0.0021 Plain to Rolled R Thumb 0.0018 0.0017 0.0015 R Index 0.0037 0.0032 0.0028 R Middle 0.0055 0.0051 0.0046 L Thumb 0.0019 0.0018 0.0016 L Index 0.0055 0.0050 0.0044 L Middle 0.0083 0.0079 0.0072 R &amp; L Thumb 0.0010 0.0010 0.0010 R &amp; L Index 0.0008 0.0007 0.0007 R &amp; L Middle 0.0018 0.0018 0.0016 Rolled to Rolled R Thumb 0.0016 0.0015 0.0013 R Index 0.0016 0.0015 0.0014 R Middle 0.0017 0.0016 0.0014 L Thumb 0.0016 0.0015 0.0014 L Index 0.0022 0.0021 0.0019 L Middle 0.0021 0.0020 0.0017 R &amp; L Thumb 0.0007 0.0007 0.0007 R &amp; L Index 0.0006 0.0006 0.0005 R &amp; L Middle 0.0007 0.0006 0.0006 "],["comparison-to-original-pft.html", "5 Comparison to Original PFT 5.1 Index Fingers", " 5 Comparison to Original PFT The Original PFT evaluation ran at NIST from 2003 until February 2010. The plots and tables in this section use identical datasets and comparison pairs as the Original PFT evaluation and are directly comparable to results posted for the Original PFT and the “Original PFT Dataset” section in PFT II reports on the NIST website: https://nist.gov/itl/iad/image-group/nist-proprietary-fingerprint-template-pft-evaluation-2003-2010 5.1 Index Fingers Figure 5.1 and Table 5.1 show the DET of index fingers over the three datasets evaluated in the Original PFT evaluation. Combined finger positions were generated by sum fusion. Figure 5.1: Detection error tradeoff of index fingers compared in the Original PFT evaluation. Combined finger positions were generated by sum fusion. Table 5.1: False non-match rate values at specific false match rates for the Original PFT dataset. Combined finger positions were generated by sum fusion. FRGP FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 Original PFT: AZ+LA County R Index 0.0047 0.0043 0.0036 L Index 0.0072 0.0067 0.0057 R &amp; L Index 0.0008 0.0006 0.0005 Original PFT: DHS 2 R Index 0.0222 0.0204 0.0179 L Index 0.0204 0.0190 0.0162 R &amp; L Index 0.0178 0.0166 0.0131 Original PFT: POE+BVA R Index 0.0011 0.0010 0.0009 L Index 0.0019 0.0017 0.0013 R &amp; L Index 0.0001 0.0000 0.0000 "],["comparison-to-minex-iii.html", "6 Comparison to MINEX III 6.1 Single Finger 6.2 Two Finger", " 6 Comparison to MINEX III Minutia Exchange (MINEX) III is NIST’s ongoing test of interoperable fingerprint template generation and matching. The only data permitted to be stored in a MINEX-compliant template are minutia type (ridge ending, bifurcation, or unknown), angle, location, and quality, as well as finger position and image quality. PFT III templates have no restrictions on the contents of the template. The results shown in this section are computed based on the exact MINEX III dataset, but using the proprietary template generator and matcher from roc+0005. Note that while ROC may be a participant in both PFT III and MINEX III (perhaps even with the same identifier of roc+0005), it does not indicate that the same underlying implementation was used. Information about equivalence of implementations should be addressed to the participant. 6.1 Single Finger Figure Figure 6.1 and Table 6.1 show single finger results, which corresponds to Figure 2 and Table 4 from any MINEX III report card. Figure 6.1: Detection error tradeoff of individual index fingers compared in the MINEX III evaluation. Table 6.1: False non-match rate values at specific false match rates for the MINEX III single finger dataset. FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 0.0019 0.0018 0.0016 6.2 Two Finger Figure 6.2 and Table 6.2 show combined two finger results (i.e., sum fusion of the single finger results), which correspond to Figure 7 and Table 7 from any MINEX III report card. Figure 6.2: Detection error tradeoff of combined index fingers compared in the MINEX III evaluation. Table 6.2: False non-match rate values at specific false match rates for the MINEX III two finger dataset. FNMR @ FMR = 0.0001 FNMR @ FMR = 0.001 FNMR @ FMR = 0.01 0.000013 0.000008 0.000004 "]]
